Application Observability and Maintenance

Understanding the API Deprecation Policy
=========================================

The Kubernetes API
-------------------

The Kubernetes API is the primary interface for Kubernetes

---
What is Deprecation?
---------------------

Deprecation is the process of providing advanced warning changes to an API, giving consumers of that API time to update their code and/or processes.

---
Deprecation Policy Highlights
------------------------------

1. apiVersion

 The apiVersion field on a Kubernetes object indicates which version of the API it is designed to be compatible with.

2. Deprecation Window
 
 Once deprecated, GA (general availability) released API versions are supported for 12 months or 3 releases (whichever is longer).

3. Migration Guide

 Check the Deprecated API Migration Guide for details on API changes with each version of Kubernetes.

---
Where to Find Deprecation Info
-------------------------------

Kubernetes Deprecation Policy: https://kubernetes.io/docs/reference/using-api/deprecation-policy/

---
Exam Tips
----------

Tip 1: API deprecation is the process of announcing changes to an API early, giving users time to update their code and/or tools.

Tip 2: Kubernetes removes support deprecated APIs that are in GA (general availability) only after 12 months or 3 Kubernetes releases, whichever is longer

===
Implementing Probes and Health Checks
======================================

What is a Probe?
-----------------

Probes are part of the container spec in Kubernetes. They allow you to customize how Kubernetes detects the state of a container.

Types of Probes
----------------

1. Liveness

 Liveness probes check whether a container is healthy so that it can be restarted if it becomes unhealthy.

2. Readiness

 Readiness probes determine when a container is fully started up and ready to receive user traffic.

3. Startup

  Startup probes check container health during startup for slow-starting containers.

Hands-On Demo
--------------

Liveness Probe

1. Create the liveness-pod.yml

apiVersion: v1
kind: Pod
metadata:
  name: liveness-pod
spec:
  containers:
  - name: busybox
    image: busybox:stable
    command: ['sh', '-c', 'while true; do sleep 10; done']
    livenessProbe:
      exec:
        command: ['echo', 'health check!']
      initalDelaySeconds: 5
      periodSeconds: 5

kubectl apply -f liveness-pod.yml

kubectl get pod liveness-pod

2. Describe the pod

  kubectl describe pod <livenes-pod-name>

Readiness Probe

1. Create the readiness-probe.yml

apiVersion: v1
kind: Pod
metadata:
  name: readiness-pod
spec:
  containers:
  - name: nginx
    image: nginx:1.20.1
    ports:
    - containerPort: 80
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 3
      periodSeconds: 3
    readinessProbe:
    httpGet:
      path: /
      port: 80
    initialDelaySeconds: 15
    periodSeconds: 5

kubectl apply -f readiness-probe.yml

2. Get the readiness pod and wait 15 seconds and try again

 kubectl get pod readiness-pod


Exam Tips
----------

Tip 1: Liveness probes check if a container is healthy so that it can be restarted if it is not.

Tip 2: Readiness probes check whether a container is fully started up and ready to be used.

Tip 3: Probes can run a command inside the container, make an HTTP request, or attempt a TCP socket connection to determine container status.	

===
Monitoring Kubernetes Applications
====================================

What is Monitoring?
--------------------

Monitoring is the process of gathering data (metrics)
 about the performance of your containerized applications.

Accessing Metrics in Kubernetes
--------------------------------

Steps to Access Data with the Metrics API:

- Install Metrics Server: This is a component that gathers the metric data so that we can access it. Without Metrics Server, the Metrics API will not provide any data.

- Access metric data: The kubectl top command can be used to view metric data once it is gathered by Metrics Server.

Hands-On Demo
--------------

1. Install the monitoring tool

kubectl apply -f https://raw.githubusercontent.com/ACloudGuru-Resources/content-cka-resources/master/metrics-server-components.yaml

2. Create the resource-consumer-pod.yml

apiVersion: v1
kind: Pod
metadata:
  name: resource-consumer-pod
spec:
  containers:
  - name: resource-consumer
    image: gcr.io/kubernetes-e2e-test-images/resource-consumer:1.5
  - name: busybox-sidecar
    image: radial/busyboxplus:curl
    command: ['sh', '-c', 'until curl localhost:8080/ConsumeCPU -d "millicores=100&durationSec=3600"; do sleep 5; done && while true; do sleep 10; done']

kubectl apply -f resource-consumer-pod.yml

3. Get the resources

  kubectl top pod

4. Get the nodes

  kubectl top node

Exam Tips
----------
Tip 1: The Kubernetes Metrics API provides metric data about container performance.

Tip 2: You can view Pod metrics using kubectl top pod.

====
Accessing Container Logs
==========================

Container Logging
------------------

Kubernetes stores the stdout/stderr console output for each container in the container log.

You can view the log with kubectl logs command.

Hands-On Demo
--------------

1. Create the logging-pod.yml

apiVersion: v1
kind: Pod
metadata:
  name: logging-pod
spec:
  containers:
  - name: busybox
    image: busybox:stable
    command: ['sh', '-c', 'while true; do echo "Writting to the log!"; sleep 5; done']

kubectl apply -f logging-pod.yml

2. Get the pod's log

  kubectl logs logging-pod

Exam Tips
----------

Tip 1: Standard/error output for containers is stored in the container log.

Tip 2: You can view the container log using kubectl logs.

Tip 3: For multi-container Pods, use the -c flag to specify which container's logs you want to view.

====
Debugging in Kubernetes
========================

The Debugging Process
----------------------

1. Locate
   
   Locate the problem. Identify which component(s) may not be working.

2. Gather Info

   Gather information about the broken components to help determine what is wrong.

3. Fix

   Make changes to fix the issue.

Kubernetes Debugging Tips
--------------------------

1. Check Object Status

   Check the basic status of objects. This can be a quick way to locate a broken Pod in the cluster.

2. Check Object Config

   Use kubectl describe and/or view the full object manifest to understand the relevant object(s) in more detail.

3. Check Logs

   Check container logs, and even cluster-level logs, for more insight into what is going on.   

Hands-On Demo
--------------

1. Create broken-pod.yml

apiVersion: v1
kind: Pod
metadata:
  name: broken-pod
spec:
  containers:
  - name: nginx
    image: nginx:1.20.q
    livenessProbe:
      httpGet:
        path: /
        port: 81
      initialDelaySeconds: 3
      periodSeconds: 3

kubectl apply -f broken-pod.yml

2. Get the pods

3. Describe the pod

  kubectl describe pod broken-pod

* The problem is the image

4. Fix the error and delete and run again

  nginx:1.20.1

* Change image and wait to change port

  port: 80

5. Another place to watch the logs is in /var/log/containers/kube-apiserver[TAB]

  cat /var/log/containers/kube-apiserver

6. Access the logs for Kubernetes

  sudo journalctl -u kubelet

Exam Tips
----------

Tip 1: Use kubectl get pods to check the status of all Pods in a Namespace. Use the --all-namespaces flag if you don't know what Namespace to look in.

Tip 2: Use kubectl describe to get detailed information about Kubernetes objects.

Tip 3: Use kubectl logs to retrieve container logs.

Tip 4: Check cluster-level logs if you still cannot locate any relevant information.